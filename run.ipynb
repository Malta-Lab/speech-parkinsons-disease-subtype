{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to run\n",
        "\n",
        "1. Create a folder in your Google Drive (for example: \"my_data\")\n",
        "2. Add your input data file (for example: data.csv) as a csv to this folder in your google drive;\n",
        "\n",
        "      The input file must be a csv file containing 16 columns, each column must contain in each row the value for the following variables for a patient:\n",
        "\n",
        "        1. nsyll_pataka\n",
        "        2. n_pausas_pataka\n",
        "        3. dur_pataka\n",
        "        4. phonationtme_pataka\n",
        "        5. speech_rate_pataka\n",
        "        6. articulationrate_pataka\n",
        "        7. asd_pataka\n",
        "        8. nsyll_monologo\n",
        "        9. n_pausas_monologo\n",
        "        10. dur_monologo\n",
        "        11. phonationtime_monologo\n",
        "        12. speechrate_monologo\n",
        "        13. articulationrate_monologo\n",
        "        14. asd_monologo\n",
        "        15. pausas_monologo\n",
        "        16. pause_ratio_monologo\n",
        "\n",
        "      Each row of the csv file must be a patient.  \n",
        "\n",
        "2. Edit the PATH_TO_OUTPUT_DIR and PATH_TO_INPUT_FILE in the cell below;\n",
        "3. Run all cells in this notebook;\n",
        "4. Predictions will be saved in the output folder indicated in the path."
      ],
      "metadata": {
        "id": "KY2NOzVX1zPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ADD THE DESIRED PATHS IN YOUR DRIVE HERE\n",
        "\n",
        "PATH_TO_INPUT_FILE = '/content/drive/MyDrive/my_data/data.csv'\n",
        "PATH_TO_OUTPUT_FOLDER = '/content/drive/MyDrive/my_data/'"
      ],
      "metadata": {
        "id": "zMZM1Zo82myk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "SGmuUmaR1yCo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOxtmVEVNSZg",
        "outputId": "9f38cabc-478d-4736-bcdf-07457b150c33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-27 17:49:59--  https://raw.githubusercontent.com/jmp-3/test-notebook/master/trained_models/kmeans_model.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4653 (4.5K) [application/octet-stream]\n",
            "Saving to: ‘kmeans_model.pkl.3’\n",
            "\n",
            "kmeans_model.pkl.3  100%[===================>]   4.54K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-08-27 17:49:59 (42.2 MB/s) - ‘kmeans_model.pkl.3’ saved [4653/4653]\n",
            "\n",
            "--2024-08-27 17:49:59--  https://raw.githubusercontent.com/jmp-3/test-notebook/master/trained_models/scaler_model.pkl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 497 [application/octet-stream]\n",
            "Saving to: ‘scaler_model.pkl.3’\n",
            "\n",
            "scaler_model.pkl.3  100%[===================>]     497  --.-KB/s    in 0s      \n",
            "\n",
            "2024-08-27 17:50:00 (27.7 MB/s) - ‘scaler_model.pkl.3’ saved [497/497]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download trained models\n",
        "!wget https://raw.githubusercontent.com/jmp-3/test-notebook/master/trained_models/kmeans_model.pkl\n",
        "!wget https://raw.githubusercontent.com/jmp-3/test-notebook/master/trained_models/scaler_model.pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9976s0d6NSZh",
        "outputId": "e445d238-d7ff-49e2-db04-614a8b2894ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator KMeans from version 1.5.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load the data from Google Drive\n",
        "loaded_data = pd.read_csv(PATH_TO_INPUT_FILE, header=None)\n",
        "\n",
        "# Load the trained KMeans model from the pickle file\n",
        "with open('kmeans_model.pkl', 'rb') as model_file:\n",
        "    loaded_model = pickle.load(model_file)\n",
        "\n",
        "# Load the scaler from the separate pickle file\n",
        "with open('scaler_model.pkl', 'rb') as scaler_file:\n",
        "    loaded_scaler = pickle.load(scaler_file)\n",
        "\n",
        "# Transform the new data using the loaded scaler\n",
        "new_data_scaled = loaded_scaler.transform(loaded_data)\n",
        "\n",
        "# Assign the new data to clusters using the loaded model\n",
        "predictions = loaded_model.predict(new_data_scaled)\n",
        "\n",
        "pd.DataFrame(predictions).to_csv(PATH_TO_OUTPUT_FOLDER + \"output.csv\", index=False, header=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "36dtQr8x9XKS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}